<!DOCTYPE html>
<html>
<body>

<h1>An Out-of-Domain Synapse Detection Challenge for Microwasp Brain Connectomes</h1>

<p>This challenge is a part of <a href="https://2023.biomedicalimaging.org/en/">ISBI 2023</a>, taking place on April 18th-21st, 2023. We will keep the online evaluation open for new submissions, but only results submitted before the challenge deadline (TBD) are considered for the ISBI 2023 challenge workshop. More information about the WASPSYN23 dataset can be found in our paper (TBA).</p>

<h2>Abstract</h2>
<p>The size of image stacks in connectomic studies now reach the terabyte or even petabyte scale with a great diversity of appearance across brain regions and samples. However, manual annotation of neural structures, e.g., synapses, are time-consuming, which leads to limited training data often smaller than 0.001% of the test data in size. Domain adaptation and generalization approaches were proposed to address similar issues for natural images, which were less evaluated on connectomics data due to the lack of out-of-domain benchmarks. This challenge aims to push the boundary of the out-of-domain generalization methods for large-scale connectomics applications. To facilitate this challenge, we painstakingly annotated 14 image chunks from a diverse set of <i>Megaphragma viggianii</i> brain regions in three whole-brain datasets. Successful algorithms that emerge from our challenge can potentially revolutionize real-world connectomics research and further efforts that aim to unravel the complexity of brain functions.</p>

<h2>Tasks Description</h2>
<p>In the <i>Megaphragma</i> brain, a synapse consists of a presynaptic terminal, accompanied by an electrondense motif called a T-bar, and multiple postsynaptic sites characterized by electron-dense regions. We design two computation tasks:</p>

<ol>
  <li><b>Presynaptic T-bar detection</b>: predict the center location of presynaptic T-bar structure from input image volumes.</li>
  <li><b>Postsynaptic site detection</b>: predict the postsynaptic site locations given the presynaptic T-bar locations and the input image volumes.</li>
</ol>

<figure>
  <img src="./images/fig1_groundtruth_data.png" alt="groundtruth_data.png" width="512" height="512">
  <figcaption>Synapse detection from 3D electron microscopy (EM) image volume. (a,b,c) The ZY, XZ, and XY planes of the 3D volume with manually annotated synapses; (d) 3D point cloud visualization of the annotated synapses: presynapses represented as yellow dots and postsynapses as cyan dots and edges connected to the corresponding presynapses.</figcaption>
</figure>

<h2>Data Description</h2>
<p>We focus on <i>Megaphragma viggianii</i> because it has both a small brain size and complex behaviour. 
These wasps have evolved anucleate neurons, likely due to the selective pressure that has driven miniaturization.
The whole head of Megaphragma was stained with heavymetal and embedded in resin. Subsequently, the sample
was imaged using enhanced Focused Ion Beam Scanning Electron Microscope (FIB-SEM) with an isotropic voxel size of 8 × 8 × 8 nm.
Following design choices were made-</p>

<ul>
<li>Cross-sample variation: We imaged three brain specimens that are illustrated in the figure below. We densely annotated 18
image chunks, each of which has 400×400×400 voxels: five chunks are from specimen one, three chunks are from specimen two, 
and ten chunks are from specimen three.</li>
<li>Cross-region variation: Different brain regions include Medulla, GNG, MB calyx, OL, VLP, AL, CBL, PLP, SLP, and etc. 
In order to challenge the generalization capability of machine learning models, we provide annotations for one volume per region 
above for the third specimen.</li>
<li>Challenging cases: In the mushroom body, multiple Kenyon cell terminals connect to an output neuron terminal, making a 
rosette-like structure. Presynaptic terminals of Kenyon cells in a rosette lack platforms and are smaller than typical T-bars.</li>
<li>Dataset split: In summary, we will use 4 volumes for training, 4 volumes for validation, and 10 volumes for testing. 
To evaluate the out-of-domain performance of models, we split the 10 annotated volumes in the third specimen into 4/1/5 for train/val/test, use the 3 volumes in
the second specimen as validation, and use the 5 volumes in the first specimen as test.</li>
</ul>
  
<figure>
  <img src="./images/fig2_images.png" alt="data_acquisatioin.png" width="512" height="512">
  <figcaption>Images from three specimens. The columns of images are XY,
XZ, and YZ planes from left to right. The images are from specimens
one to three from top to bottom. The arrows indicate T-bars identified
in the section. The red arrows indicate T-bars from mushroom bodies
specifically.</figcaption>
</figure>
  

<h2>Publication Policy</h2>
<p>The three top-performing teams are eligible to participate in a joint publication with the committee submitting to IEEE Transactions on Medical Imaging (TMI). There is a fixed maximum of two authors per team. The committee will also invite teams that submit particularly novel solutions to join as co-authors.</p>

<h2>Award Policy</h2>
<p>Certificates will be awarded to challenge
top-3 teams (1 winner and 2 runner-ups). An iPad and two
ebook readers will also be awarded to the top-3 teams.</p>

<h2>Important Dates</h2>
<ul>
<li><b>Jan. 1st, 2023: </b>Website launch; release
of training, validation, and single-phase test data
in H5 format; code for metric computation; example
submission and utility functions on GitHub</li>
<li><b>Jan. 1st, 2023 -  Feb. 28th, 2023: </b>Registration and submission period.</li>
<li><b>Mar. 1st, 2023: </b>Leaderboard release and invitation for workshop
manuscript submission.</li>
<li><b>Apr. 18th, 2023: </b>Presentations at the workshop.</li>
</ul>


<h2>Organising Committee</h2>
<ul>
<li><a href="https://www.simonsfoundation.org/people/jingpeng-wu/">Jingpeng Wu, Associate Research Scientist, Neural Circuits and Algorithms, CCN, Flatiron Institute, New York, U.S.A.</a></li>
<li><a href="https://yicong-li.github.io/">Yicong Li, Ph.D. Student in Computer Science, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, U.S.A.</a></li>
<li><a href="https://www.simonsfoundation.org/people/kazunori-shinomiya/">Kazunori Shinomiya, Research Scientist, Neural Circuits and Algorithms, CCN, Flatiron Institute, New York, U.S.A.</a></li>
<li><a href="https://www.simonsfoundation.org/people/pat-gunn/">Pat Gunn, Senior Software Engineer, SCC, Flatiron Institute, New York, U.S.A.</a></li>
<li><a href="http://entomology.bio.msu.ru/en/about-2/people/polilov/">Alexey Polilov, Professor of the Russian Academy of Sciences, Head of the Department of Entomology, Faculty of Biology, Lomonosov Moscow State University, Moscow, Russia</a></li>
<li><a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister, An Wang Professor of Computer Science, John A. Paulson School of Engineering and Applied Sciences, Harvard University, U.S.A.</a></li>
<li><a href="https://www.simonsfoundation.org/people/dmitri-mitya-chklovskii/">Dmitri
Chklovskii, Group Leader, Neural Circuits and Algorithms, CCN, Flatiron Institute, New York, U.S.A.</a></li>
<li><a href="https://donglaiw.github.io/">Donglai Wei, Assistant Professor of Computer Science, Boston College, Boston, U.S.A.</a></li>
</ul>

</body>
</html>

